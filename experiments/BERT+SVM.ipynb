{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d358e62",
      "metadata": {
        "id": "8d358e62"
      },
      "source": [
        "##Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78049da6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78049da6",
        "outputId": "a62c9334-4c25-451e-db6b-5e7a6908726e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "path=\"hamvsspam.csv\"\n",
        "\n",
        "df = pd.read_csv(\"hamvsspam.csv\", encoding='latin1')\n",
        "\n",
        "# Keep only the first two columns (label and message)\n",
        "df = df.iloc[:, :2]\n",
        "\n",
        "# Rename the columns\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc54a0c",
      "metadata": {
        "id": "0bc54a0c"
      },
      "outputs": [],
      "source": [
        "\n",
        "X=df['message']\n",
        "y=df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "073e00c7",
      "metadata": {
        "id": "073e00c7"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.25,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_l = X_train.tolist()\n",
        "X_test_l = X_test.tolist()\n"
      ],
      "metadata": {
        "id": "YgxOtfoEweKe"
      },
      "id": "YgxOtfoEweKe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3406071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3406071",
        "outputId": "654b4a75-913a-46d6-cbbd-d65f8bf5d329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hf_xet in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       1.00      1.00      1.00      4987\n",
            "        spam       1.00      1.00      1.00       767\n",
            "\n",
            "    accuracy                           1.00      5754\n",
            "   macro avg       1.00      1.00      1.00      5754\n",
            "weighted avg       1.00      1.00      1.00      5754\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      0.99      1645\n",
            "        spam       0.98      0.96      0.97       274\n",
            "\n",
            "    accuracy                           0.99      1919\n",
            "   macro avg       0.99      0.98      0.98      1919\n",
            "weighted avg       0.99      0.99      0.99      1919\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install hf_xet\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Set up model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.eval()\n",
        "\n",
        "def get_bert_embeddings_batched(texts, batch_size=16):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        encodings = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**encodings)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "            embeddings.append(cls_embeddings.cpu().numpy())\n",
        "    return np.concatenate(embeddings, axis=0)\n",
        "\n",
        "# Assume `train_texts` and `test_texts` are lists of strings\n",
        "X_train_embb = get_bert_embeddings_batched(X_train_l)\n",
        "X_test_embb = get_bert_embeddings_batched(X_test_l)\n",
        "\n",
        "# Train SVM\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train_embb, y_train)\n",
        "\n",
        "y_pred_train = svm.predict(X_train_embb)\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "\n",
        "y_pred_test = svm.predict(X_test_embb)\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}